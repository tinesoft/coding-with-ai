# Assessment Rubric: AI Agent Instruction Files

**Module**: Module 2 - Modern AI Coding Tools  
**Assessment**: Agent Instruction File Quality Evaluation  
**Scoring**: 5-Point Scale (0-5 points per criterion)

## Evaluation Criteria

### 1. Completeness (0-5 points)

#### 5 - Exceptional
- **Project Architecture**: Complete system architecture documentation with diagrams
- **Development Workflow**: Detailed development, testing, and deployment processes
- **Technology Stack**: Comprehensive list of all dependencies with versions
- **Code Style**: Complete style guide with examples and enforcement tools
- **Build Instructions**: Step-by-step build and deployment procedures

#### 4 - Proficient
- **Project Architecture**: Clear architecture overview with key components
- **Development Workflow**: Main development processes documented
- **Technology Stack**: Primary dependencies and tools listed
- **Code Style**: Basic style guidelines provided
- **Build Instructions**: Essential build steps included

#### 3 - Developing
- **Project Architecture**: Basic structure documented
- **Development Workflow**: Some processes mentioned
- **Technology Stack**: Core technologies identified
- **Code Style**: Some style preferences noted
- **Build Instructions**: Basic build information provided

#### 2 - Beginning
- **Project Architecture**: Minimal structure information
- **Development Workflow**: Limited process documentation
- **Technology Stack**: Few technologies mentioned
- **Code Style**: Inconsistent style information
- **Build Instructions**: Incomplete build guidance

#### 1 - Inadequate
- **Project Architecture**: Unclear or missing structure
- **Development Workflow**: No clear processes
- **Technology Stack**: Missing or incorrect information
- **Code Style**: No style guidance
- **Build Instructions**: Missing or incorrect instructions

#### 0 - Not Present
- Missing essential completeness elements

### 2. Project-Specific Context (0-5 points)

#### 5 - Exceptional
- **Unique Patterns**: All critical architectural patterns identified and explained
- **Business Logic**: Domain-specific logic clearly documented with examples
- **Integration Points**: All external services and APIs documented with specifications
- **Domain Terminology**: Comprehensive glossary of project-specific terms
- **Custom Conventions**: All project-specific conventions clearly explained

#### 4 - Proficient
- **Unique Patterns**: Key architectural patterns documented
- **Business Logic**: Main business rules explained
- **Integration Points**: Primary integrations documented
- **Domain Terminology**: Important terms defined
- **Custom Conventions**: Main conventions explained

#### 3 - Developing
- **Unique Patterns**: Some patterns identified
- **Business Logic**: Basic business context provided
- **Integration Points**: Some integrations noted
- **Domain Terminology**: Few terms explained
- **Custom Conventions**: Some conventions mentioned

#### 2 - Beginning
- **Unique Patterns**: Limited pattern recognition
- **Business Logic**: Minimal context provided
- **Integration Points**: Few integrations mentioned
- **Domain Terminology**: Minimal term definitions
- **Custom Conventions**: Limited convention documentation

#### 1 - Inadequate
- **Unique Patterns**: Generic patterns only
- **Business Logic**: No specific context
- **Integration Points**: Missing integration information
- **Domain Terminology**: No specialized terms
- **Custom Conventions**: Standard conventions only

#### 0 - Not Present
- Missing project-specific context elements

### 3. Actionable Guidance (0-5 points)

#### 5 - Exceptional
- **Clear Instructions**: Step-by-step guidance for common tasks
- **Decision Trees**: Flowcharts for complex decisions
- **Error Handling**: Comprehensive troubleshooting guides
- **Best Practices**: Detailed best practice explanations with rationale
- **Examples**: Multiple real-world examples for each concept

#### 4 - Proficient
- **Clear Instructions**: Good guidance for main tasks
- **Decision Trees**: Some decision support provided
- **Error Handling**: Basic troubleshooting information
- **Best Practices**: Key best practices documented
- **Examples**: Some examples provided

#### 3 - Developing
- **Clear Instructions**: Basic task guidance
- **Decision Trees**: Limited decision support
- **Error Handling**: Some error guidance
- **Best Practices**: Few best practices noted
- **Examples**: Limited examples

#### 2 - Beginning
- **Clear Instructions**: Unclear or incomplete guidance
- **Decision Trees**: Minimal decision support
- **Error Handling**: Limited error information
- **Best Practices**: Few practices mentioned
- **Examples**: Very few examples

#### 1 - Inadequate
- **Clear Instructions**: Confusing or incorrect guidance
- **Decision Trees**: No decision support
- **Error Handling**: Missing error guidance
- **Best Practices**: No best practices
- **Examples**: No meaningful examples

#### 0 - Not Present
- Missing actionable guidance elements

## Scoring Summary

### Total Score Calculation
- **Maximum Score**: 15 points (5 + 5 + 5)
- **Passing Score**: 12 points (80% threshold per SC-007)

### Grade Conversion
- **13-15 points**: Exceptional (A)
- **12 points**: Proficient (B) - Meets Success Criteria
- **9-11 points**: Developing (C)
- **6-8 points**: Beginning (D)
- **0-5 points**: Inadequate (F)

## Evaluation Process

### 1. Initial Review
- Read instruction file completely
- Identify which AI platforms are addressed (GitHub Copilot, Claude, Gemini, unified AGENTS.md)
- Note overall structure and organization

### 2. Criterion Assessment
- Score each criterion independently using the detailed rubrics above
- Provide specific feedback for each criterion
- Note exemplary elements and areas for improvement

### 3. Final Evaluation
- Calculate total score
- Determine if success criteria (SC-007) are met
- Provide overall feedback and recommendations

## Success Criteria Validation

### SC-007 Compliance Check
- **Requirement**: 80% of learners successfully create comprehensive AI agent instruction files
- **Measurement**: Score of 12/15 points or higher
- **Validation**: Files demonstrably improve AI agent performance through trainer evaluation

### SC-008 Compliance Check
- **Requirement**: Learners identify at least 5 critical project-specific patterns
- **Measurement**: Project-Specific Context criterion must score 3+ points with evidence of 5+ patterns
- **Validation**: Architecture patterns, build systems, conventions clearly documented

## Trainer Notes

### Common Issues to Watch For
- Generic instruction files without project-specific context
- Missing or incorrect build/setup instructions
- Vague business logic explanations
- Lack of concrete examples
- Inconsistent formatting across AI platform files

### Best Practice Examples
- Clear separation between platform-specific files (copilot-instructions.md, CLAUDE.md, GEMINI.md) and unified AGENTS.md
- Specific code examples with project context
- Decision flowcharts for complex architectural choices
- Troubleshooting sections with common issues and solutions
- Links to relevant documentation and resources